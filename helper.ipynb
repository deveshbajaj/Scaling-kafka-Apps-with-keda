{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer\n",
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "import time\n",
    "from confluent_kafka import SerializingProducer, DeserializingConsumer\n",
    "from confluent_kafka.serialization import StringSerializer, StringDeserializer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['keda-scalling', '__consumer_offsets']"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all past topics\n",
    "KAFKA_BOOTSTRAP_SERVERS = \"localhost:29092\"\n",
    "consumer_conf = {\n",
    "        \"bootstrap.servers\": KAFKA_BOOTSTRAP_SERVERS,\n",
    "        \"group.id\": \"anygroup\",\n",
    "        \"auto.offset.reset\": \"earliest\",\n",
    "        \"security.protocol\": \"plaintext\",\n",
    "        \"enable.auto.commit\": False,\n",
    "    }\n",
    "\n",
    "consumer = Consumer(consumer_conf)\n",
    "list(consumer.list_topics().topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic created!\n"
     ]
    }
   ],
   "source": [
    "# Make new topics\n",
    "topic = \"keda-scalling\"\n",
    "admin_conf = {\n",
    "        \"bootstrap.servers\": KAFKA_BOOTSTRAP_SERVERS,\n",
    "    }\n",
    "admin_client = AdminClient(admin_conf)\n",
    "topic_list = []\n",
    "topic_list.append(NewTopic(topic=topic, num_partitions=5, replication_factor=1))\n",
    "resp = admin_client.create_topics(new_topics=topic_list, validate_only=False)\n",
    "time.sleep(5)\n",
    "if resp.get(topic).result() is None:\n",
    "    print(\"topic created!\")\n",
    "else:\n",
    "    print(resp.get(topic).result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message delivered to keda-scalling [0]\n",
      "Message delivered to keda-scalling [0]\n",
      "Message delivered to keda-scalling [0]\n",
      "Message delivered to keda-scalling [1]\n",
      "Message delivered to keda-scalling [1]\n",
      "Message delivered to keda-scalling [2]\n",
      "Message delivered to keda-scalling [2]\n",
      "Message delivered to keda-scalling [2]\n",
      "Message delivered to keda-scalling [3]\n",
      "Message delivered to keda-scalling [3]\n"
     ]
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# producer script \n",
    "import json\n",
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        print('Message delivery failed: {}'.format(err))\n",
    "    else:\n",
    "        print('Message delivered to {} [{}]'.format(msg.topic(), msg.partition()))\n",
    "\n",
    "\n",
    "\n",
    "producer_conf = {\n",
    "    \"bootstrap.servers\": KAFKA_BOOTSTRAP_SERVERS,\n",
    "    \"value.serializer\": StringSerializer(),\n",
    "}\n",
    "producer = SerializingProducer(producer_conf)\n",
    "\n",
    "for i in range(10):\n",
    "    producer.poll(0)\n",
    "    data = {\n",
    "        \"name\" : f\"name_{i}\",\n",
    "        \"address\" :  \"LOL\"\n",
    "    }\n",
    "    res = producer.produce(topic, value=json.dumps(data), on_delivery=delivery_report)\n",
    "producer.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}